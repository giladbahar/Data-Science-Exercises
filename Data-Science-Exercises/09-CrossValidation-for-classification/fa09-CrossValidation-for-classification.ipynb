{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "![Final Lesson Exercise](images/Banner_FEX.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Lesson #9: Cross validation and classification\n",
    "## Edible and Poisonous Mushrooms dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## About this assignment\n",
    "In this assignment, you will explore information regarding mushrooms.<br/>\n",
    "\n",
    "This time you will practice the cross validation techniques to select best classifiers.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external packages. \n",
    "\n",
    "**Use the following libraries for the assignment, when needed**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# === CELL TYPE: IMPORTS AND SETUP \n",
    "\n",
    "import os                       # for testing use only\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# -------- classification\n",
    "import sklearn\n",
    "from sklearn import neighbors, tree, ensemble, naive_bayes, svm\n",
    "# *** KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# *** Decision Tree; Random Forest\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# *** Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# *** SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "# --------  metrics:\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"dataset_desc\"></a>\n",
    "[go to basic data exploration](#data_exploration)\n",
    "## The mushroom dataset\n",
    "In this exercise you will work with the mushroom dataset.<br/>\n",
    "**The mushroom dataset, describes two types of mushrooms**:<br/>\n",
    "e - edible, p - poisonous.\n",
    "\n",
    "**The following is a list of features in the dataset**:\n",
    "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n",
    "4. bruises?: bruises=t,no=f\n",
    "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
    "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "7. gill-spacing: close=c,crowded=w,distant=d\n",
    "8. gill-size: broad=b,narrow=n\n",
    "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n",
    "10. stalk-shape: enlarging=e,tapering=t\n",
    "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n",
    "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "16. veil-type: partial=p,universal=u\n",
    "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "18. ring-number: none=n,one=o,two=t\n",
    "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n",
    "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n",
    "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n",
    "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\n",
    "\n",
    "[go to basic data exploration](#data_exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 1. Load the dataset and prepare dataset for classification\n",
    "In this section you will perform the following actions:\n",
    "* 1.a. Load the mushrooms dataset\n",
    "* 1.b. Basic data exploration\n",
    "* 1.c. Prepare data for classification\n",
    "* 1.d. Split dataset to train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1.a. Load the mushrooms dataset \n",
    "In this section you will load the mushrooms dataset from a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1.a. Instructions\n",
    "<u>method name</u>: <b>load_dataset</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'load_dataset' function to load the mushroom dataset from the 'file_name' csv file\n",
    "  into a pandas dataframe.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return df_dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def load_dataset(file_name):\n",
    "    \n",
    "    df_dataset = pd.read_csv(file_name)\n",
    "    return df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       class cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
      "count   8127      8127        8127      8126    8127  8127            8127   \n",
      "unique     2         6           4        10       2     9               2   \n",
      "top        e         x           y         n       f     n               f   \n",
      "freq    4208      3657        3246      2285    4751  3528            7917   \n",
      "\n",
      "       gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "count          8127      8127       8127  ...                     8127   \n",
      "unique            2         2         12  ...                        4   \n",
      "top               c         b          b  ...                        s   \n",
      "freq           6815      5613       1730  ...                     4937   \n",
      "\n",
      "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "count                    8127                   8127      8127       8127   \n",
      "unique                      9                      9         1          4   \n",
      "top                         w                      w         p          w   \n",
      "freq                     4465                   4384      8127       7927   \n",
      "\n",
      "       ring-number ring-type spore-print-color population habitat  \n",
      "count         8127      8126              8127       8127    8127  \n",
      "unique           3         5                 9          6       7  \n",
      "top              o         p                 w          v       d  \n",
      "freq          7491      3968              2390       4042    3148  \n",
      "\n",
      "[4 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "print(raw_dataset.describe())\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.a. \n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1a-1_load_dataset",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.a. - Test 1 (name: test1a-1_load_dataset, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'load_dataset' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'load_dataset' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.a. - Test 1 (name: test1a-1_load_dataset, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'load_dataset' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'load_dataset' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1a-2_load_dataset",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.a. - Test 2 (name: test1a-2_load_dataset, points: 0.1)\n",
      "\t--->Testing the implementation of 'load_dataset' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'load_dataset' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.a. - Test 2 (name: test1a-2_load_dataset, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'load_dataset' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert raw_dataset.shape == (8127, 23) , 'Wrong shape for dataset dataframe'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'load_dataset' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"data_exploration\"></a>\n",
    "### 1.b. Basic data exploration\n",
    "In this section you may perform simple processing on the dataset to understand it better.\n",
    "\n",
    "* Perform simple dataset exploration. It is suggested to use describe, info and a simple histogram for features' values\n",
    "* You could see also the [explanation of the dataset above](#dataset_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: DATA EXPLORATION\n",
    "# Perform a simple dataset exploration. \n",
    "# It is sugggested to use describe, info and a simple histogram for features' values\n",
    "# Transfer dataset's values to numeric ones.\n",
    "# Use the output of the exploration for next section.\n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1.c. Prepare data for classification\n",
    "In this section you will the <u>prepare data in the dataset for classification</u>.\n",
    "\n",
    "* Use the results of your [data exploration above](#data_exploration)\n",
    "* See also the [explanation of the dataset above](#dataset_desc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1.c. Instructions\n",
    "<u>method name</u>: <b>transfer_str_to_numeric_vals</b>\n",
    "<pre>The following is expected:\n",
    "\n",
    "- Remove any rows with one or more missing value. \n",
    "- For any duplicate rows, keep only the first one \n",
    "- Transfer dataset's values to numeric ones.\n",
    " Notes:\n",
    "       Each unique string value should be transfered to a corresponding \n",
    "           unique numeric integer value.\n",
    "       All the columns contain string values, as described above.\n",
    "       It is suggested todo this in a generic way for all columns (you can do this part in two lines of code)\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def transfer_str_to_numeric_vals(dataset):\n",
    "    \n",
    "    dataset = dataset.dropna()\n",
    "     \n",
    "    dataset = dataset.drop_duplicates()\n",
    "    \n",
    "    dataset = dataset.apply(lambda col: col.astype('category').cat.codes if col.dtypes == 'object' else col)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 4, 10, 2, 9, 2, 2, 2, 12, 2, 5, 4, 4, 9, 9, 1, 4, 3, 5, 9, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "dataset = transfer_str_to_numeric_vals(raw_dataset)\n",
    "cols = dataset.select_dtypes(include=[np.number])\n",
    "arr_nums = [len(dataset[col].unique()) for col in cols]\n",
    "print(arr_nums)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.c. \n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1c-1_transfer_str_to_numeric_vals",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.c. - Test 1 (name: test1c-1_transfer_str_to_numeric_vals, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'transfer_str_to_numeric_vals' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.c. - Test 1 (name: test1c-1_transfer_str_to_numeric_vals, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    dataset = transfer_str_to_numeric_vals(raw_dataset)\n",
    "    cols = dataset.select_dtypes(include=[np.number])\n",
    "    arr_nums = [len(dataset[col].unique()) for col in cols]\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'transfer_str_to_numeric_vals' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1c-2_transfer_str_to_numeric_vals",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.c. - Test 2 (name: test1c-2_transfer_str_to_numeric_vals, points: 0.1)\n",
      "\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'transfer_str_to_numeric_vals' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.c. - Test 2 (name: test1c-2_transfer_str_to_numeric_vals, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    dataset = transfer_str_to_numeric_vals(raw_dataset)\n",
    "    cols = dataset.select_dtypes(include=[np.number])\n",
    "    arr_nums = [len(dataset[col].unique()) for col in cols]\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert dataset.shape == (8124, 23) , 'Wrong shape for dataset dataframe'\n",
    "assert dataset.select_dtypes(include=[np.number]).columns.size == 23, 'Wrong number of numeric columns'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'transfer_str_to_numeric_vals' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1c-3_transfer_str_to_numeric_vals",
     "locked": true,
     "points": "0.2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.c. - Test 3 (name: test1c-3_transfer_str_to_numeric_vals, points: 0.2)\n",
      "\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'transfer_str_to_numeric_vals' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.c. - Test 3 (name: test1c-3_transfer_str_to_numeric_vals, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    dataset = transfer_str_to_numeric_vals(raw_dataset)\n",
    "    cols = dataset.select_dtypes(include=[np.number])\n",
    "    arr_nums = [len(dataset[col].unique()) for col in cols]\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert np.round(np.mean(arr_nums),2)==5.17,'Wrong number of unique values'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'transfer_str_to_numeric_vals' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1.d. Split dataset to train and test\n",
    "In this section you will split the dataset into a train set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1.d. Instructions\n",
    "<u>method name</u>: <b>split_to_train_and_test</b>\n",
    "<pre>The following is expected:\n",
    "Step 1 - Split the given dataset into 'X' (feature vectors - dataframe)\n",
    "      and 'y' (corresponding labels - series), determined by the given 'label_column' column.\n",
    "Step 2 - Split X and y into 'X_train', 'X_test', and corresponding 'y_train' and 'y_test' series.\n",
    "Notes: \n",
    "      The 'X_train' and 'X_test' dataframes should not include the 'label_column' column.\n",
    "      Use sklearn's 'train_test_split' method, which was taught in class.\n",
    "      Use the given 'rand_state' as the value for the 'random_state' parameter in 'train_test_split'.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return X_train, X_test, y_train, y_test</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def split_to_train_and_test(dataset, label_column, test_ratio, rand_state):\n",
    "    X = dataset.drop(columns=[label_column])\n",
    "    y = dataset[label_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=rand_state) \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6499, 22) (1625, 22) (6499,) (1625,)\n"
     ]
    }
   ],
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "dataset = transfer_str_to_numeric_vals(raw_dataset) \n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.d. \n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1d-1_split_to_train_and_test",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.d. - Test 1 (name: test1d-1_split_to_train_and_test, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'split_to_train_and_test' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'split_to_train_and_test' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.d. - Test 1 (name: test1d-1_split_to_train_and_test, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'split_to_train_and_test' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    dataset = transfer_str_to_numeric_vals(raw_dataset) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'split_to_train_and_test' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1d-2_split_to_train_and_test",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.d. - Test 2 (name: test1d-2_split_to_train_and_test, points: 0.1)\n",
      "\t--->Testing the implementation of 'split_to_train_and_test' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'split_to_train_and_test' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.d. - Test 2 (name: test1d-2_split_to_train_and_test, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'split_to_train_and_test' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    dataset = transfer_str_to_numeric_vals(raw_dataset) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "\n",
    "assert X_train.shape == (6499, 22) and X_test.shape == (1625, 22), 'Wrong shape for feature-vector train or test dataframes'\n",
    "assert y_train.shape[0] == 6499 and y_test.shape[0] == 1625, 'Wrong shape for category train or test series'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'split_to_train_and_test' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 2. Auxiliary classification function\n",
    "This section includes the following:\n",
    "* 2.a. get classifier object \n",
    "* 2.b. get evaluation value on test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2.a. get classifier object auxiliary function\n",
    "\n",
    "The following 'get_classifier_obj' auxiliary function contain 2 input parameters:\n",
    "- classifier_name\n",
    "- params\n",
    "\n",
    "And outputs the corresponding classifier\n",
    "\n",
    "**The 'classifier_name' parameter**, contains a <u>string value</u><br />\n",
    "   and indicates which classifier object to return, as following<br />\n",
    "* if 'classifier_name' equals 'KNN' return 'KNeighborsClassifier()'\n",
    "* if 'classifier_name' equals 'naive_bayes' return 'GaussianNB()'\n",
    "* if 'classifier_name' equals 'svm' return 'SVC()'\n",
    "* if 'classifier_name' equals 'decision_tree' return 'tree.DecisionTreeClassifier()'\n",
    "* if 'classifier_name' equals 'random_forest ' return 'RandomForestClassifier()'\n",
    "\n",
    "**<u>The 'param' parameter</u>** is a <u>dictionary object</u>.<br />\n",
    "It could be 'None' or contain values as following:<br />\n",
    "* If **'classifier_name' equals 'KNN'**:\n",
    "    It will contain a value for the <u>'n_neighbors'</u> key in the 'param' parameter.\n",
    "    * Set this ('n_neighbors') parameter in the returned 'KNeighborsClassifier' object accordingly.\n",
    "* If **'classifier_name' equals 'decision_tree'**:\n",
    "    It will contain a value for the <u>'max_depth' & 'min_samples_split'</u> keys in the 'param' parameter.\n",
    "    * Set these ('max_depth', 'min_samples_split') parameters in the 'DecisionTreeClassifier' object accordingly.\n",
    "* If **'classifier_name' equals 'random_forest'**:\n",
    "    It will contain a value for the <u>'n_estimators'</u> key in the 'param' parameter.\n",
    "    * Set this ('n_estimators') parameter in the 'RandomForestClassifier' object accordingly.\n",
    "* If **'classifier_name' equals 'naive_bayes' or 'svm'**, assume the 'params' will be equal None.\n",
    "    * In such a case return the relevant GaussianNB object or SVC object without setting any parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2.a. Some examples\n",
    "\n",
    "**Example 1**: The <u>'classifier_name' parameter equals 'KNN' and the 'param' parameter is not None</u>, <br />\n",
    "return a classifier object as following:<br/ >\n",
    "return KNeighborsClassifier(n_neighbors=params['n_neighbors'])\n",
    "\n",
    "**Example 2**: The <u>'classifier_name' parameter equals 'KNN' and the 'param' parameter is None</u>,<br />\n",
    "return a classifier object as following:<br />\n",
    "return KNeighborsClassifier()\n",
    "\n",
    "**Example 3**: The 'classifier_name' parameter equals 'svm',\n",
    "return a classifier object as following:<br />\n",
    "return SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2.a. Instructions\n",
    "<u>method name</u>: <b>get_classifier_obj</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'get_classifier_obj' auxiliary function to return\n",
    "    a classifier object, as explained above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return clf</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def get_classifier_obj(classifier_name, params):\n",
    "    clf = None\n",
    "\n",
    "    if classifier_name == 'KNN':\n",
    "        if params and 'n_neighbors' in params:\n",
    "            clf = KNeighborsClassifier(n_neighbors=params['n_neighbors'])\n",
    "        else:\n",
    "            clf = KNeighborsClassifier()\n",
    "    elif classifier_name == 'naive_bayes':\n",
    "        clf = GaussianNB()\n",
    "    elif classifier_name == 'svm':\n",
    "        clf = SVC()\n",
    "    elif classifier_name == 'decision_tree':\n",
    "        if params and 'max_depth' in params and 'min_samples_split' in params:\n",
    "            clf = DecisionTreeClassifier(max_depth=params['max_depth'], min_samples_split=params['min_samples_split'])\n",
    "        else:\n",
    "            clf = DecisionTreeClassifier()\n",
    "    elif classifier_name == 'random_forest':\n",
    "        if params and 'n_estimators' in params:\n",
    "            clf = RandomForestClassifier(n_estimators=params['n_estimators'])\n",
    "        else:\n",
    "            clf = RandomForestClassifier()\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "params_knn = {'n_neighbors':3}\n",
    "params_random_forest = {'n_estimators':51}\n",
    "params_decision_tree = {'max_depth':4, 'min_samples_split':4}\n",
    "clf_naive_bayes = get_classifier_obj(\"naive_bayes\",None)\n",
    "clf_svm = get_classifier_obj(\"svm\",None)\n",
    "clf_knn = get_classifier_obj(\"KNN\",None)\n",
    "clf_random_forest = get_classifier_obj(\"random_forest\",None)\n",
    "clf_decision_tree = get_classifier_obj(\"decision_tree\",None)\n",
    "clf_knn_with_params = get_classifier_obj(\"KNN\",params_knn)\n",
    "clf_random_forest_with_params = get_classifier_obj(\"random_forest\",params_random_forest)    \n",
    "clf_decision_tree_with_params = get_classifier_obj(\"decision_tree\",params_decision_tree)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.a. \n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-1_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 1 (name: test2a-1_get_classifier_obj, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'get_classifier_obj' function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 1 (name: test2a-1_get_classifier_obj, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "\n",
    "params_knn = {'n_neighbors':3}\n",
    "params_random_forest = {'n_estimators':51}\n",
    "params_decision_tree = {'max_depth':4, 'min_samples_split':4}\n",
    "try:\n",
    "    clf_naive_bayes = get_classifier_obj(\"naive_bayes\",None)\n",
    "    clf_svm = get_classifier_obj(\"svm\",None)\n",
    "    clf_knn = get_classifier_obj(\"KNN\",None)\n",
    "    clf_random_forest = get_classifier_obj(\"random_forest\",None)\n",
    "    clf_decision_tree = get_classifier_obj(\"decision_tree\",None)\n",
    "    clf_knn_with_params = get_classifier_obj(\"KNN\",params_knn)\n",
    "    clf_random_forest_with_params = get_classifier_obj(\"random_forest\",params_random_forest)    \n",
    "    clf_decision_tree_with_params = get_classifier_obj(\"decision_tree\",params_decision_tree)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'get_classifier_obj' function :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-2_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 2 (name: test2a-2_get_classifier_obj, points: 0.1)\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'get_classifier_obj' (for 'Naive Nayes') function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 2 (name: test2a-2_get_classifier_obj, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "try:\n",
    "    clf = get_classifier_obj(\"naive_bayes\",None)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert type(clf) == sklearn.naive_bayes.GaussianNB , 'Wrong type for classifier'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'get_classifier_obj' (for 'Naive Nayes') function :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-3_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 3 (name: test2a-3_get_classifier_obj, points: 0.1)\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'get_classifier_obj' (for 'SVM') function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 3 (name: test2a-3_get_classifier_obj, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "try:\n",
    "    clf = get_classifier_obj(\"svm\",None)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert type(clf) == sklearn.svm._classes.SVC , 'Wrong type for classifier'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'get_classifier_obj' (for 'SVM') function :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-4i_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 4i (name: test2a-4i_get_classifier_obj, points: 0.1)\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 4th test (without paramaters) for the 'get_classifier_obj' (for 'KNN') function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 4i (name: test2a-4i_get_classifier_obj, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "try:\n",
    "    clf = get_classifier_obj(\"KNN\",None)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert type(clf) == sklearn.neighbors._classification.KNeighborsClassifier , 'Wrong type for classifier'\n",
    "assert clf.n_neighbors == 5 , 'Wrong value for n_neighbors in KNN, expected default value'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 4th test (without paramaters) for the 'get_classifier_obj' (for 'KNN') function :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-4ii_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 4ii (name: test2a-4ii_get_classifier_obj, points: 0.1)\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 4th test (with paramaters) for the 'get_classifier_obj' (for 'KNN') function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 4ii (name: test2a-4ii_get_classifier_obj, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "params = {'n_neighbors':3}\n",
    "try:\n",
    "    clf = get_classifier_obj(\"KNN\",params)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert type(clf) == sklearn.neighbors._classification.KNeighborsClassifier , 'Wrong type for classifier'\n",
    "assert clf.n_neighbors == 3 , 'Wrong value for n_neighbors in KNN, expected to be equal to input value'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 4th test (with paramaters) for the 'get_classifier_obj' (for 'KNN') function :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-5i_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 5i (name: test2a-5i_get_classifier_obj, points: 0.1)\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 5th test (without paramaters) for the 'get_classifier_obj' (for' Random Forest') function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 5i (name: test2a-5i_get_classifier_obj, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "try:\n",
    "    clf = get_classifier_obj(\"random_forest\",None)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert type(clf) == sklearn.ensemble._forest.RandomForestClassifier , 'Wrong type for classifier'\n",
    "assert clf.n_estimators == 100 , 'Wrong value for n_estimators in random forest, expected default value'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 5th test (without paramaters) for the 'get_classifier_obj' (for' Random Forest') function :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-5ii_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 5ii (name: test2a-5ii_get_classifier_obj, points: 0.1)\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 5th test (with paramaters) for the 'get_classifier_obj' (for' Random Forest') function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 5ii (name: test2a-5ii_get_classifier_obj, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "params = {'n_estimators':51}\n",
    "\n",
    "try:\n",
    "    clf = get_classifier_obj(\"random_forest\",params)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert type(clf) == sklearn.ensemble._forest.RandomForestClassifier , 'Wrong type for classifier'\n",
    "assert clf.n_estimators == 51 , 'Wrong value for n_estimators in random forest, expected to be equal to input value'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 5th test (with paramaters) for the 'get_classifier_obj' (for' Random Forest') function :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-6i_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 6i (name: test2a-6i_get_classifier_obj, points: 0.1)\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 6th test (without paramaters) for the 'get_classifier_obj' (for 'Decision Tree') function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 6i (name: test2a-6i_get_classifier_obj, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "try:\n",
    "    clf = get_classifier_obj(\"decision_tree\",None)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert type(clf) == sklearn.tree._classes.DecisionTreeClassifier , 'Wrong type for classifier'\n",
    "assert clf.max_depth is None and clf.min_samples_split==2 , 'Wrong values for max_depth or min_samples_split in Decision Tree, expected default value'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 6th test (without paramaters) for the 'get_classifier_obj' (for 'Decision Tree') function :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2a-6ii_get_classifier_obj",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.a. - Test 6ii (name: test2a-6ii_get_classifier_obj, points: 0.1)\n",
      "\t--->Testing the implementation of 'get_classifier_obj' ...\n",
      "Good Job!\n",
      "You've passed the 6th test (with paramaters) for the 'get_classifier_obj' (for 'Decision Tree') function :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.a. - Test 6ii (name: test2a-6ii_get_classifier_obj, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_classifier_obj' ...\")\n",
    "\n",
    "params = {'max_depth':4, 'min_samples_split':4}\n",
    "try:\n",
    "    clf = get_classifier_obj(\"decision_tree\",params)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert type(clf) == sklearn.tree._classes.DecisionTreeClassifier , 'Wrong type for classifier'\n",
    "assert clf.max_depth==4 and clf.min_samples_split==4 , 'Wrong values for max_depth or min_samples_split in Decision Tree, expected to be equal to input values'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 6th test (with paramaters) for the 'get_classifier_obj' (for 'Decision Tree') function :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2.b. get evaluation value on test auxiliary function\n",
    "\n",
    "The following **'calc_evaluation_val'** auxiliary function contain <u>3 input parameters</u>:\n",
    "- eval_metric - the evaluation metric expected to return\n",
    "- y_test      - the actual test target categories\n",
    "- y_predicted - the predicted test categories\n",
    "\n",
    "**The 'eval_metric' parameter**, contains a <u>string value</u><br />\n",
    "   and indicates which evaluation metric, which object to return, as following:<br />\n",
    "* if 'eval_metric' equals <u>'accuracy'</u> return the <u>accuracy_score</u> evaluation float value\n",
    "* if 'eval_metric' equals <u>'precision'</u> return the <u>precision_score</u> evaluation float value\n",
    "* if 'eval_metric' equals <u>'recall'</u> return the <u>recall_score</u> evaluation float value\n",
    "* if 'eval_metric' equals <u>'f1'</u> return the <u>f1_score</u> evaluation float value\n",
    "* if 'eval_metric' equals <u>'confusion_matrix'</u> return the <u>confusion_matrix</u> evaluation np.ndarray value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2.b. Instructions\n",
    "<u>method name</u>: <b>calc_evaluation_val</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'calc_evaluation_val' auxiliary function to return\n",
    "    the evaluation value of the trained model, as explained above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return evaluation_val</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def calc_evaluation_val(eval_metric, y_test, y_predicted):\n",
    "    evaluation_val = None\n",
    "    \n",
    "    if eval_metric == 'accuracy':\n",
    "        evaluation_val = accuracy_score(y_test, y_predicted)\n",
    "    elif eval_metric == 'precision':\n",
    "        evaluation_val = precision_score(y_test, y_predicted)\n",
    "    elif eval_metric == 'recall':\n",
    "        evaluation_val = recall_score(y_test, y_predicted)\n",
    "    elif eval_metric == 'f1':\n",
    "        evaluation_val = f1_score(y_test, y_predicted)\n",
    "    elif eval_metric == 'confusion_matrix':\n",
    "        evaluation_val = confusion_matrix(y_test, y_predicted)\n",
    "    \n",
    "    return evaluation_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "y_test = pd.Series([1,0,1,0,1,0,1,0,1,0])\n",
    "y_predicted = pd.Series([1,1,1,1,1,1,1,0,0,0])\n",
    "accuracy_val = calc_evaluation_val(\"accuracy\", y_test, y_predicted)\n",
    "precision_val = calc_evaluation_val(\"precision\", y_test, y_predicted)\n",
    "recall_val = calc_evaluation_val(\"recall\", y_test, y_predicted)\n",
    "f1_val = calc_evaluation_val(\"f1\", y_test, y_predicted)\n",
    "confusion_matrix_val = calc_evaluation_val(\"confusion_matrix\", y_test, y_predicted)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.b. \n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2b-1_calc_evaluation_val",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.b. - Test 1 (name: test2b-1_calc_evaluation_val, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'calc_evaluation_val' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'calc_evaluation_val' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.b. - Test 1 (name: test2b-1_calc_evaluation_val, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'calc_evaluation_val' ...\")\n",
    "\n",
    "try:\n",
    "    y_test = pd.Series([1,0,1,0,1,0,1,0,1,0])\n",
    "    y_predicted = pd.Series([1,1,1,1,1,1,1,0,0,0])\n",
    "    accuracy_val = calc_evaluation_val(\"accuracy\", y_test, y_predicted)\n",
    "    precision_val = calc_evaluation_val(\"precision\", y_test, y_predicted)\n",
    "    recall_val = calc_evaluation_val(\"recall\", y_test, y_predicted)\n",
    "    f1_val = calc_evaluation_val(\"f1\", y_test, y_predicted)\n",
    "    confusion_matrix_val = calc_evaluation_val(\"confusion_matrix\", y_test, y_predicted)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'calc_evaluation_val' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2b-2_calc_evaluation_val",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.b. - Test 2 (name: test2b-2_calc_evaluation_val, points: 0.1)\n",
      "\t--->Testing the implementation of 'calc_evaluation_val' ...\n",
      "accuracy: 0.6\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'calc_evaluation_val' function implementation (for 'accuracy') :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.b. - Test 2 (name: test2b-2_calc_evaluation_val, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'calc_evaluation_val' ...\")\n",
    "\n",
    "try:\n",
    "    y_test = pd.Series([1,0,1,0,1,0,1,0,1,0])\n",
    "    y_predicted = pd.Series([1,1,1,1,1,1,1,0,0,0])\n",
    "    evaluation_val = calc_evaluation_val(\"accuracy\", y_test, y_predicted)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert 0.6 == np.round(evaluation_val,2),\"Wrong 'accuracy' value\"\n",
    "\n",
    "print(\"accuracy:\",evaluation_val)\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'calc_evaluation_val' function implementation (for 'accuracy') :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2b-3_calc_evaluation_val",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.b. - Test 3 (name: test2b-3_calc_evaluation_val, points: 0.1)\n",
      "\t--->Testing the implementation of 'calc_evaluation_val' ...\n",
      "precision: 0.5714285714285714\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'calc_evaluation_val' function implementation (for 'precision') :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.b. - Test 3 (name: test2b-3_calc_evaluation_val, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'calc_evaluation_val' ...\")\n",
    "\n",
    "try:\n",
    "    y_test = pd.Series([1,0,1,0,1,0,1,0,1,0])\n",
    "    y_predicted = pd.Series([1,1,1,1,1,1,1,0,0,0])\n",
    "    evaluation_val = calc_evaluation_val(\"precision\", y_test, y_predicted)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert 0.57 == np.round(evaluation_val,2),\"Wrong 'precision' value\"\n",
    "\n",
    "print(\"precision:\",evaluation_val)\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'calc_evaluation_val' function implementation (for 'precision') :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2b-4_calc_evaluation_val",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.b. - Test 4 (name: test2b-4_calc_evaluation_val, points: 0.1)\n",
      "\t--->Testing the implementation of 'calc_evaluation_val' ...\n",
      "recall: 0.8\n",
      "Good Job!\n",
      "You've passed the 4th test for the 'calc_evaluation_val' function implementation (for 'recall') :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.b. - Test 4 (name: test2b-4_calc_evaluation_val, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'calc_evaluation_val' ...\")\n",
    "\n",
    "try:\n",
    "    y_test = pd.Series([1,0,1,0,1,0,1,0,1,0])\n",
    "    y_predicted = pd.Series([1,1,1,1,1,1,1,0,0,0])\n",
    "    evaluation_val = calc_evaluation_val(\"recall\", y_test, y_predicted)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert 0.8 == np.round(evaluation_val,2),\"Wrong 'recall' value\"\n",
    "\n",
    "print(\"recall:\",evaluation_val)\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 4th test for the 'calc_evaluation_val' function implementation (for 'recall') :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2b-5_calc_evaluation_val",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.b. - Test 5 (name: test2b-5_calc_evaluation_val, points: 0.1)\n",
      "\t--->Testing the implementation of 'calc_evaluation_val' ...\n",
      "f1: 0.6666666666666666\n",
      "Good Job!\n",
      "You've passed the 5th test for the 'calc_evaluation_val' function implementation (for 'f1') :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.b. - Test 5 (name: test2b-5_calc_evaluation_val, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'calc_evaluation_val' ...\")\n",
    "\n",
    "try:\n",
    "    y_test = pd.Series([1,0,1,0,1,0,1,0,1,0])\n",
    "    y_predicted = pd.Series([1,1,1,1,1,1,1,0,0,0])\n",
    "    evaluation_val = calc_evaluation_val(\"f1\", y_test, y_predicted)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert 0.67 == np.round(evaluation_val,2),\"Wrong 'f1' value\"\n",
    "\n",
    "print(\"f1:\",evaluation_val)\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 5th test for the 'calc_evaluation_val' function implementation (for 'f1') :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test2b-6_calc_evaluation_val",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2.b. - Test 6 (name: test2b-6_calc_evaluation_val, points: 0.1)\n",
      "\t--->Testing the implementation of 'calc_evaluation_val' ...\n",
      "confusion_matrix:\n",
      "---------------------\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                   2                   3\n",
      "Actual Positive                   1                   4\n",
      "Good Job!\n",
      "You've passed the 6th test for the 'calc_evaluation_val' function implementation (for 'confusion matrix') :-)\n"
     ]
    }
   ],
   "source": [
    "# 2.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 2.b. - Test 6 (name: test2b-6_calc_evaluation_val, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'calc_evaluation_val' ...\")\n",
    "\n",
    "try:\n",
    "    y_test = pd.Series([1,0,1,0,1,0,1,0,1,0])\n",
    "    y_predicted = pd.Series([1,1,1,1,1,1,1,0,0,0])\n",
    "    evaluation_val = calc_evaluation_val(\"confusion_matrix\", y_test, y_predicted)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert np.ndarray==type(evaluation_val),'Wrong evaluation value for confusion matrix'\n",
    "\n",
    "assert 1 == evaluation_val[1,0],\"Wrong 'False Negative' value\"\n",
    "\n",
    "print(\"confusion_matrix:\\n---------------------\")\n",
    "df_confusion_matrix = pd.DataFrame(evaluation_val,index=['Actual Negative','Actual Positive'],columns=['Predicted Negative','Predicted Positive'])\n",
    "print(df_confusion_matrix)\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 6th test for the 'calc_evaluation_val' function implementation (for 'confusion matrix') :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 3. Grid Search Cross-validation - hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 3.a. KNN - find best K for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 3.a. Instructions\n",
    "<u>method name</u>: <b>find_best_k_for_KNN</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'find_best_k_for_KNN' function to find the K-hyperparameter (i.e. the \n",
    "     'n_neighbors' parameter) for the KNN algorithm, running on the mushroom \n",
    "     dataset's train-set, using grid search cross validation 'GridSearchCV' function.\n",
    "Notes:\n",
    "      You need to use the average f1 score, in order to choose the best K \n",
    "         for this dataset.\n",
    "      Use the 3,7,9,11 possible values as possibilities to the 'n_neighbors' parameter.\n",
    "      You need to return the best K value as well as the best average f1 score.\n",
    "      Use the 'make_scorer', as the function for 'scoring' parameter\n",
    "</pre>      \n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return best_K, best_f1_val</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def find_best_k_for_KNN(X_train, y_train):\n",
    "    neighbors = {\"n_neighbors\": [3, 7, 9, 11]}\n",
    "    knn = KNeighborsClassifier()\n",
    "    clf = GridSearchCV(knn, neighbors, scoring=make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_k = clf.best_params_[\"n_neighbors\"]\n",
    "    best_f1_val = clf.best_score_\n",
    "    return best_k, best_f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "best_K, best_f1_KNN_params = find_best_k_for_KNN(X_train, y_train)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.a. \n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3a-1_find_best_k_for_KNN",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.a. - Test 1 (name: test3a-1_find_best_k_for_KNN, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'find_best_k_for_KNN' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'find_best_k_for_KNN' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.a. - Test 1 (name: test3a-1_find_best_k_for_KNN, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_k_for_KNN' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "    dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "    best_K, best_f1_KNN_params = find_best_k_for_KNN(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'find_best_k_for_KNN' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3a-2_find_best_k_for_KNN",
     "locked": true,
     "points": "0.4",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.a. - Test 2 (name: test3a-2_find_best_k_for_KNN, points: 0.4)\n",
      "\t--->Testing the implementation of 'find_best_k_for_KNN' ...\n",
      "... successful\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'find_best_k_for_KNN' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.a. - Test 2 (name: test3a-2_find_best_k_for_KNN, points: 0.4)\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_k_for_KNN' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "    dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "found_assertion_combination = False    \n",
    "for i in range(50):\n",
    "    try:\n",
    "        best_K, best_f1_KNN_params = find_best_k_for_KNN(X_train, y_train)\n",
    "        ###\n",
    "        ### AUTOGRADER TEST - DO NOT REMOVE\n",
    "        ###\n",
    "        assert best_K==7,'Wrong best K hyperparameter value for KNN'\n",
    "        found_assertion_combination = True\n",
    "        print ('... successful')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print ('Try:',i+1,'failed')\n",
    "        print ('\\tError Message:', str(e))\n",
    "        print ('Will try again ...')\n",
    "\n",
    "assert found_assertion_combination,'Wrong best K hyperparameter value for KNN'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'find_best_k_for_KNN' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3a-3_find_best_k_for_KNN",
     "locked": true,
     "points": "0.4",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.a. - Test 3 (name: test3a-3_find_best_k_for_KNN, points: 0.4)\n",
      "\t--->Testing the implementation of 'find_best_k_for_KNN' ...\n",
      "... successful\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'find_best_k_for_KNN' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.a. - Test 3 (name: test3a-3_find_best_k_for_KNN, points: 0.4)\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_k_for_KNN' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "    dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "found_assertion_combination = False\n",
    "for i in range(50):\n",
    "    try:\n",
    "        best_K, best_f1_KNN_params = find_best_k_for_KNN(X_train, y_train)\n",
    "        ###\n",
    "        ### AUTOGRADER TEST - DO NOT REMOVE\n",
    "        ###\n",
    "        assert 0.993==np.round(best_f1_KNN_params,3),'Wrong F1 value for best K (number of neigbors) for KNN'        \n",
    "        found_assertion_combination = True\n",
    "        print ('... successful')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print ('Try:',i+1,'failed')\n",
    "        print ('\\tError Message:', str(e))\n",
    "        print ('Will try again ...')\n",
    "\n",
    "assert found_assertion_combination, 'Wrong F1 value for best K (number of neigbors) for KNN'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'find_best_k_for_KNN' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 3.b. Decision tree - find best parameter pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 3.b. Instructions\n",
    "<u>method name</u>: <b>find_best_decision_tree_params</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'find_best_decision_tree_params' function to find best\n",
    "          'max_depth' and 'min_samples_split' hyperparameter pair,\n",
    "          for the decision-trees algorithm, running on the mushroom dataset.\n",
    "     Again, use the grid search cross validation 'GridSearchCV' function.\n",
    "Notes:\n",
    "       You need to use the average f1 score, in order to choose the best  \n",
    "           'max_depth' and 'min_samples_split' hyperparameter pair for this dataset.\n",
    "       Use 2,4,6 as possible values as possibilities for the 'max_depth' parameter\n",
    "           and 5,10,20 for 'min_samples_split'.\n",
    "       You need to return the value of best 'max_depth', 'min_samples_split' pair\n",
    "           and best average f1 score.\n",
    "       Use the 'make_scorer', as the function for 'scoring' parameter\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return best_max_depth, best_min_samples_split, best_f1_val</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def find_best_decision_tree_params(X_train, y_train):\n",
    "    parameters = {\"max_depth\": [2, 4, 6], \"min_samples_split\": [5, 10, 20]}\n",
    "    dtree = tree.DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(dtree, parameters, scoring=make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_max_depth = clf.best_params_[\"max_depth\"]\n",
    "    best_min_samples_split = clf.best_params_[\"min_samples_split\"]\n",
    "    best_f1_val = clf.best_score_\n",
    "    return best_max_depth, best_min_samples_split, best_f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "best_max_dep, best_min_smpl_splt, best_f1_DT_params = find_best_decision_tree_params(X_train, y_train)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3b-1_find_best_decision_tree_params",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.b. - Test 1 (name: test3b-1_find_best_decision_tree_params, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'find_best_decision_tree_params' ...\n",
      "\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'find_best_decision_tree_params' method :-)\n"
     ]
    }
   ],
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.b. - Test 1 (name: test3b-1_find_best_decision_tree_params, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_decision_tree_params' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "    dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "    best_max_dep, best_min_smpl_splt, best_f1_DT_params = find_best_decision_tree_params(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "         \n",
    "print (\"\\nGood Job!\\nYou've passed the 1st test for the 'find_best_decision_tree_params' method :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3b-2_find_best_decision_tree_params",
     "locked": true,
     "points": "0.4",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.b. - Test 2 (name: test3b-2_find_best_decision_tree_params, points: 0.4)\n",
      "\t--->Testing the implementation of 'find_best_decision_tree_params' ...\n",
      "... successful\n",
      "\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'find_best_decision_tree_params' method :-)\n"
     ]
    }
   ],
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.b. - Test 2 (name: test3b-2_find_best_decision_tree_params, points: 0.4)\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_decision_tree_params' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "    dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "found_assertion_combination = False\n",
    "for i in range(50):\n",
    "    try:\n",
    "        best_max_dep, best_min_smpl_splt, best_f1_DT_params = find_best_decision_tree_params(X_train, y_train)\n",
    "        ###\n",
    "        ### AUTOGRADER TEST - DO NOT REMOVE\n",
    "        ###\n",
    "        assert best_max_dep==4 and best_min_smpl_splt==5,'Wrong best Decision-tree hyperparameter pair values'\n",
    "        found_assertion_combination = True\n",
    "        print ('... successful')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print ('Try:',i+1,'failed')\n",
    "        print ('\\tError Message:', str(e))\n",
    "        print ('Will try again ...')\n",
    "\n",
    "assert found_assertion_combination,'Wrong best Decision-tree hyperparameter pair values'\n",
    "         \n",
    "print (\"\\nGood Job!\\nYou've passed the 2nd test for the 'find_best_decision_tree_params' method :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3b-3_find_best_decision_tree_params",
     "locked": true,
     "points": "0.4",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.b. - Test 3 (name: test3b-3_find_best_decision_tree_params, points: 0.4)\n",
      "\t--->Testing the implementation of 'find_best_decision_tree_params' ...\n",
      "\n",
      "\t====> Full grading test - the following test can not be seen before submission\n"
     ]
    }
   ],
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.b. - Test 3 (name: test3b-3_find_best_decision_tree_params, points: 0.4)\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_decision_tree_params' ...\")\n",
    "print (\"\\n\\t====> Full grading test - the following test can not be seen before submission\")\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 3.c. Random forest - find best number of estimators parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 3.c. Instructions\n",
    "<u>method name</u>: <b>find_best_random_forest_num_estimators</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'find_best_random_forest_num_estimators' function to find best\n",
    "    'n_estimators' hyperparameter values, \n",
    "     for the random-forest algorithm, running on the mushroom dataset's train-set.\n",
    "     Again, use the grid search cross validation 'GridSearchCV' function.\n",
    "Notes:\n",
    "       You need to use the average f1 score, in order to choose the best  \n",
    "           'n_estimators' hyperparameter for this dataset.\n",
    "       Use 11,51,71 as possible values as possibilities for the \n",
    "           'n_estimators' parameter.\n",
    "       You need to return the value of 'n_estimators' best value \n",
    "           and the best average f1 score.\n",
    "       Use the 'make_scorer', as the function for 'scoring' parameter     \n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return best_num_estimators, best_f1_val</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def find_best_random_forest_num_estimators(X_train, y_train):\n",
    "    parameters = {\"n_estimators\": [11, 51, 71]}\n",
    "    rf = RandomForestClassifier()\n",
    "    clf = GridSearchCV(rf, parameters, scoring=make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_num_estimators = clf.best_params_[\"n_estimators\"]\n",
    "    best_f1_val = clf.best_score_\n",
    "    return best_num_estimators, best_f1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "best_n_estimators, best_f1_RF_params = find_best_random_forest_num_estimators(X_train, y_train)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3c-1_find_best_random_forest_num_estimators",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.c. - Test 1 (name: test3c-1_find_best_random_forest_num_estimators, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'find_best_random_forest_num_estimators' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'find_best_random_forest_num_estimators' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.c. - Test 1 (name: test3c-1_find_best_random_forest_num_estimators, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_random_forest_num_estimators' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "    dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "    best_n_estimators, best_f1_RF_params = find_best_random_forest_num_estimators(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'find_best_random_forest_num_estimators' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3c-2_find_best_random_forest_num_estimators",
     "locked": true,
     "points": "0.4",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.c. - Test 2 (name: test3c-2_find_best_random_forest_num_estimators, points: 0.4)\n",
      "\t--->Testing the implementation of 'find_best_random_forest_num_estimators' ...\n",
      "\tError Message: Wrong best num-estimator hyperparameter value for Random-Forest\n",
      "Will try again, num-try: 1\n",
      "\tError Message: Wrong best num-estimator hyperparameter value for Random-Forest\n",
      "Will try again, num-try: 2\n",
      "\tError Message: Wrong best num-estimator hyperparameter value for Random-Forest\n",
      "Will try again, num-try: 3\n",
      "\tError Message: Wrong best num-estimator hyperparameter value for Random-Forest\n",
      "Will try again, num-try: 4\n",
      "\tError Message: Wrong best num-estimator hyperparameter value for Random-Forest\n",
      "Will try again, num-try: 5\n",
      "\tError Message: Wrong best num-estimator hyperparameter value for Random-Forest\n",
      "Will try again, num-try: 6\n",
      "\tError Message: Wrong best num-estimator hyperparameter value for Random-Forest\n",
      "Will try again, num-try: 7\n",
      "... successful\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'find_best_random_forest_num_estimators' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.c. - Test 2 (name: test3c-2_find_best_random_forest_num_estimators, points: 0.4)\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_random_forest_num_estimators' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    sub_set_of_raw_dataset_2k_4k = raw_dataset.iloc[2000:4000,:]\n",
    "    dataset = transfer_str_to_numeric_vals(sub_set_of_raw_dataset_2k_4k) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "found_assertion_combination = False\n",
    "for i in range(50):\n",
    "    try:\n",
    "        best_n_estimators, best_f1_RF_params = find_best_random_forest_num_estimators(X_train, y_train)\n",
    "        ###\n",
    "        ### AUTOGRADER TEST - DO NOT REMOVE\n",
    "        ###\n",
    "        assert best_n_estimators==71,'Wrong best num-estimator hyperparameter value for Random-Forest'\n",
    "        found_assertion_combination = True\n",
    "        print ('... successful')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print ('\\tError Message:', str(e))\n",
    "        print ('Will try again, num-try:',i+1)\n",
    "\n",
    "assert found_assertion_combination,'Wrong best num-estimator hyperparameter value for Random-Forest'\n",
    "         \n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'find_best_random_forest_num_estimators' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3c-3_find_best_random_forest_num_estimators",
     "locked": true,
     "points": "0.4",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.c. - Test 3 (name: test3c-3_find_best_random_forest_num_estimators, points: 0.4)\n",
      "\t--->Testing the implementation of 'find_best_random_forest_num_estimators' ...\n",
      "\n",
      "\t====> Full grading test - the following test can not be seen before submission\n"
     ]
    }
   ],
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.c. - Test 3 (name: test3c-3_find_best_random_forest_num_estimators, points: 0.4)\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_random_forest_num_estimators' ...\")\n",
    "print (\"\\n\\t====> Full grading test - the following test can not be seen before submission\")\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 4. Select The best model\n",
    "In this section you need to select the best model using the \n",
    "  average cross validation recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 4. Instructions\n",
    "<u>method name</u>: <b>find_best_model</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'find_best_model' function to find best\n",
    "    trained model out of the following three models:\n",
    "    Model 1: Decision Trees model (with given 'max_depth' and 'min_samples_split' parameters)\n",
    "    Model 2: (Gaussian) Naive Bayes model (with default parameters). \n",
    "    Model 3: SVM model (SVC with default parameters).\n",
    "Notes:\n",
    "       You need to use the average recall score, in order to choose the best  \n",
    "           trained classification model.\n",
    "       You need to return the best trained classifier object and the best average recall score.\n",
    "          The average score, should be performed on a 10-fold cross validation.\n",
    "          Use the 'cross_val_score' method to calculate the best average score.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return best_clf, best_recall_val</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def find_best_model(X_train, y_train, max_depth_val, min_samples_split_val):\n",
    "    parameters = {\"max_depth\": max_depth_val, \"min_samples_split\": min_samples_split_val}\n",
    "    best_clf = None\n",
    "    best_recall_val = -1\n",
    "    algos = [\"svm\", \"naive_bayes\", \"decision_tree\"]\n",
    "\n",
    "    for alg in algos:\n",
    "        clf = get_classifier_obj(alg, parameters)\n",
    "        \n",
    "        #  -cross_val_score  10-fold cross-validation\n",
    "        recall_scores = cross_val_score(clf, X_train, y_train, cv=10, scoring=\"recall\")\n",
    "        avg_recall = recall_scores.mean()  #    recall\n",
    "        \n",
    "        if avg_recall > best_recall_val:\n",
    "            best_recall_val = avg_recall\n",
    "            best_clf = clf\n",
    "\n",
    "    return best_clf, best_recall_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "max_dep=4\n",
    "min_smpl_splt=5\n",
    "raw_dataset = load_dataset(file_name)\n",
    "dataset = transfer_str_to_numeric_vals(raw_dataset) \n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "best_clf, best_recall_val=find_best_model(X_train, y_train, max_dep, min_smpl_splt)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4-1_find_best_model",
     "locked": true,
     "points": "0.1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4. - Test 1 (name: test4-1_find_best_model, points: 0.1) - sanity\n",
      "\t--->Testing the implementation of 'find_best_model' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'find_best_model' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 4.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4. - Test 1 (name: test4-1_find_best_model, points: 0.1) - sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_model' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "max_dep=4\n",
    "min_smpl_splt=5\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    dataset = transfer_str_to_numeric_vals(raw_dataset) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "    best_clf, best_recall_val=find_best_model(X_train, y_train, max_dep, min_smpl_splt)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'find_best_model' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4-2_find_best_model",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4. - Test 2 (name: test4-2_find_best_model, points: 0.5)\n",
      "\t--->Testing the implementation of 'find_best_model' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'find_best_model' function implementation :-)\n"
     ]
    }
   ],
   "source": [
    "# 4.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4. - Test 2 (name: test4-2_find_best_model, points: 0.5)\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_model' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mushrooms.csv'\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'class'\n",
    "max_dep=4\n",
    "min_smpl_splt=5\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    dataset = transfer_str_to_numeric_vals(raw_dataset) \n",
    "    X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "    best_clf, best_recall_val=find_best_model(X_train, y_train, max_dep, min_smpl_splt)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "\n",
    "assert type(best_clf) == sklearn.tree._classes.DecisionTreeClassifier , 'Wrong type for best classifier'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'find_best_model' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4-3_find_best_model",
     "locked": true,
     "points": "0.4",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4. - Test 3 (name: test4-3_find_best_model, points: 0.4)\n",
      "\t--->Testing the implementation of 'find_best_model' ...\n",
      "\n",
      "\t====> Full grading test - the following test can not be seen before submission\n"
     ]
    }
   ],
   "source": [
    "# 4.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4. - Test 3 (name: test4-3_find_best_model, points: 0.4)\")\n",
    "print (\"\\t--->Testing the implementation of 'find_best_model' ...\")\n",
    "print (\"\\n\\t====> Full grading test - the following test can not be seen before submission\")\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
